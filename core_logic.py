import os
import base64
import json
import asyncio
import queue
import threading
import time
import concurrent.futures
from difflib import SequenceMatcher
from fastapi import FastAPI, WebSocket, WebSocketDisconnect
from fastapi.responses import HTMLResponse
import uvicorn
from core_logic import ReservationAI
import re 

# Google Cloud ãƒ©ã‚¤ãƒ–ãƒ©ãƒª
from google.oauth2 import service_account
from google.cloud import texttospeech
from google.cloud import speech

app = FastAPI()

# --- è¨­å®š ---
gemini_key = os.environ.get("GEMINI_API_KEY")
if not gemini_key:
    print("âš ï¸ è­¦å‘Š: GEMINI_API_KEY ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")

# AIã‚¨ãƒ³ã‚¸ãƒ³åˆæœŸåŒ–
ai_engine = ReservationAI(gemini_key)

# èªè¨¼æƒ…å ±ã®èª­ã¿è¾¼ã¿
CREDENTIALS_FILE = "google.json"
creds = None
if os.path.exists(CREDENTIALS_FILE):
    creds = service_account.Credentials.from_service_account_file(CREDENTIALS_FILE)
    print("âœ… Google Cloud èªè¨¼æˆåŠŸ (google.json)")
else:
    print("âŒ ã‚¨ãƒ©ãƒ¼: google.json ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")

# ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆæœŸåŒ–
tts_client = texttospeech.TextToSpeechClient(credentials=creds) if creds else None
stt_client = speech.SpeechClient(credentials=creds) if creds else None

# STTè¨­å®š (STTèªè­˜å¼·åŒ–é©ç”¨æ¸ˆã¿ - STTã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆç¶­æŒ)
STT_CONFIG = speech.RecognitionConfig(
    encoding=speech.RecognitionConfig.AudioEncoding.LINEAR16,
    sample_rate_hertz=16000,
    language_code="ja-JP",
    enable_automatic_punctuation=True,

    # Speech Context (Recognition Context) - é›»è©±ç•ªå·èªè­˜å¼·åŒ–
    speech_contexts=[
        speech.SpeechContext(
            phrases=['090', '1234', '5678', 'ã‚¼ãƒ­ã‚­ãƒ¥ã‚¦ã‚¼ãƒ­', 'ã‚¤ãƒãƒ‹ãƒ¼ã‚µãƒ³ãƒ¨ãƒ³', 'ã‚´ãƒ¼ãƒ­ã‚¯ãƒŠãƒŠãƒãƒ'],
            boost=20.0
        ),
        speech.SpeechContext(
            phrases=['é›»è©±ç•ªå·', '090-1234-5678', '09012345678'],
            boost=10.0
        ),
        # æ•°å­—åˆ—ã®èªè­˜ã‚’å®‰å®šã•ã›ã‚‹ãŸã‚ã®ãƒ’ãƒ³ãƒˆ
        speech.SpeechContext(
            phrases=['1', '2', '3', '4', '5', '6', '7', '8', '9', '0', 'ã§ã™'],
            boost=5.0
        )
    ]
)
STREAMING_CONFIG = speech.StreamingRecognitionConfig(
    config=STT_CONFIG,
    interim_results=True,
    single_utterance=False
)

executor = concurrent.futures.ThreadPoolExecutor(max_workers=3)
connection_states = {}

# å±¥æ­´ã‹ã‚‰SSMLã‚¿ã‚°ã‚’å‰Šé™¤ã™ã‚‹é–¢æ•°
def clean_ssml_from_history(history: list):
    clean_history = []
    for entry in history:
        # <prosody...>ã‚¿ã‚°ã‚„ãã®ä»–ã®XMLã‚¿ã‚°ã‚’å…¨ã¦é™¤å»
        clean_text = re.sub(r'<[^>]+>', '', entry['text']) 
        clean_history.append({"role": entry['role'], "text": clean_text})
    return clean_history

def synthesize_speech_sync(text):
    if not tts_client: return None
    try:
        # SSMLã‚¿ã‚°ãŒå«ã¾ã‚Œã¦ã„ã‚‹å ´åˆã¯ã€ã‚¿ã‚¤ãƒ—ã‚’SSMLã«è¨­å®š
        synthesis_input = texttospeech.SynthesisInput(text=text)
        if '<prosody' in text or '<speak>' in text:
             synthesis_input = texttospeech.SynthesisInput(ssml=text)

        voice = texttospeech.VoiceSelectionParams(
            language_code="ja-JP",
            name="ja-JP-Chirp3-HD-Leda"
        )
        audio_config = texttospeech.AudioConfig(
            audio_encoding=texttospeech.AudioEncoding.MP3,
            speaking_rate=1.0
        )
        response = tts_client.synthesize_speech(
            input=synthesis_input, voice=voice, audio_config=audio_config
        )
        return base64.b64encode(response.audio_content).decode('utf-8')
    except Exception as e:
        print(f"âŒ TTSã‚¨ãƒ©ãƒ¼: {e}")
        return None

async def synthesize_speech(text):
    """åŒæœŸçš„ãªTTSé–¢æ•°ã‚’éåŒæœŸã‚¹ãƒ¬ãƒƒãƒ‰ã§å®Ÿè¡Œ"""
    loop = asyncio.get_event_loop()
    return await loop.run_in_executor(executor, synthesize_speech_sync, text)

async def process_conversation_async(user_text, history):
    loop = asyncio.get_event_loop()
    return await loop.run_in_executor(executor, ai_engine.process_conversation, user_text, history)

async def select_smart_ack_async(user_text):
    loop = asyncio.get_event_loop()
    return await loop.run_in_executor(executor, ai_engine.select_smart_acknowledgment, user_text)

async def send_json_safe(websocket: WebSocket, data: dict):
    try:
        await websocket.send_json(data)
    except Exception:
        pass

# ã‚¨ã‚³ãƒ¼åˆ¤å®š
def is_semantic_echo(transcript, ai_text):
    if not ai_text or not transcript: return False
    def normalize(text):
        # SSMLã‚¿ã‚°ã‚’é™¤å»ã—ã¦ã‹ã‚‰æ¯”è¼ƒ
        text = re.sub(r'<[^>]+>', '', text)
        return text.replace(" ", "").replace("ã€€", "").replace("ã€‚", "").replace("ã€", "").strip()

    t_norm = normalize(transcript)
    a_norm = normalize(ai_text)

    # 1. å®Œå…¨ä¸€è‡´
    if t_norm == a_norm: return True

    # 2. åŒ…å« (çŸ­ã„è¨€è‘‰ã¯å…ˆé ­/æœ«å°¾ä¸€è‡´ã®ã¿)
    if t_norm in a_norm:
        if len(t_norm) <= 2:
            return a_norm.startswith(t_norm) or a_norm.endswith(t_norm)
        return True 

    # 3. é¡ä¼¼åº¦ï¼ˆé–¾å€¤ 0.8 ã«è¨­å®šï¼‰
    ratio = SequenceMatcher(None, t_norm, a_norm).ratio()
    if ratio > 0.90: return True 

    return False

@app.get("/")
async def get():
    with open("templates/phone.html", "r", encoding="utf-8") as f:
        return HTMLResponse(f.read())

@app.websocket("/ws")
async def websocket_endpoint(websocket: WebSocket):
    await websocket.accept()
    print("âœ… WebSocketæ¥ç¶šé–‹å§‹")

    # ==========================================================
    # â˜…ãƒ—ãƒªãƒ•ã‚§ãƒƒãƒé–‹å§‹
    # ==========================================================
    reserver_name = ai_engine.RESERVATION_INFO['reserver_name']
    default_intro = f"ãŠå¿™ã—ã„ã¨ã“ã‚æã‚Œå…¥ã‚Šã¾ã™ã€‚ç§ã€{reserver_name}ã®AIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚äºˆç´„ã‚’ãŠé¡˜ã„ã§ãã¾ã™ã§ã—ã‚‡ã†ã‹ã€‚"

    intro_text = getattr(ai_engine, "INTRO_TEXT", default_intro)

    print(f"ğŸš€ [Prefetch] ç¬¬ä¸€å£°ã®ç”Ÿæˆã‚’é–‹å§‹: {intro_text[:15]}...")
    intro_task = asyncio.create_task(synthesize_speech(intro_text)) 

    audio_queue = queue.Queue()
    loop = asyncio.get_event_loop()
    is_connected = True

    # çŠ¶æ…‹ç®¡ç†ï¼ˆhistoryã‚’å«ã‚ã¦æ°¸ç¶šåŒ–ï¼‰
    state = {
        "is_first_interaction": True,
        "current_ai_text": "",
        "intro_task": intro_task,  
        "history": []              
    }

    connection_states[websocket] = state

    def run_stt_loop():
        nonlocal is_connected
        def request_generator():
            while is_connected:
                try:
                    chunk = audio_queue.get(timeout=0.1)
                    if chunk is None: return
                    yield speech.StreamingRecognizeRequest(audio_content=chunk)
                except queue.Empty:
                    yield speech.StreamingRecognizeRequest(audio_content=b'\x00' * 3200)

        while is_connected:
            try:
                responses = stt_client.streaming_recognize(STREAMING_CONFIG, request_generator())
                for response in responses:
                    if not is_connected: break
                    if not response.results: continue
                    result = response.results[0]
                    if not result.alternatives: continue

                    transcript = result.alternatives[0].transcript
                    is_final = result.is_final

                    current_ai_text = state["current_ai_text"]
                    if is_semantic_echo(transcript, current_ai_text):
                        if is_final: print(f"ğŸ”‡ ã‚¨ã‚³ãƒ¼é™¤å»: '{transcript}'")
                        continue

                    asyncio.run_coroutine_threadsafe(
                        send_json_safe(websocket, {"type": "transcript", "text": transcript, "is_final": is_final}),
                        loop
                    )

                    if is_final:
                        print(f"ğŸ—£ï¸ èªè­˜ç¢ºå®š: {transcript}")
                        state["current_ai_text"] = ""
                        # ä¼šè©±å‡¦ç†ã¸
                        asyncio.run_coroutine_threadsafe(
                            handle_conversation_flow(websocket, transcript, state),
                            loop
                        )
            except Exception as e:
                if is_connected: time.sleep(1)
                else: break

    stt_thread = threading.Thread(target=run_stt_loop, daemon=True)
    stt_thread.start()

    try:
        while True:
            message = await websocket.receive()
            if "bytes" in message:
                audio_queue.put(message["bytes"])
            elif "text" in message:
                data = json.loads(message["text"])
                if data.get("event") == "interrupt":
                    print("ğŸ›‘ å‰²ã‚Šè¾¼ã¿å—ä¿¡")
                    state["current_ai_text"] = ""
    except WebSocketDisconnect:
        print("ğŸ‘‹ WebSocketåˆ‡æ–­")
    except Exception as e:
        print(f"âŒ WebSocketã‚¨ãƒ©ãƒ¼: {e}")
    finally:
        is_connected = False
        audio_queue.put(None)
        # ã‚¿ã‚¹ã‚¯ãŒå®Œäº†ã—ã¦ã„ãªã‘ã‚Œã°ã‚­ãƒ£ãƒ³ã‚»ãƒ«
        if not state["intro_task"].done():
            state["intro_task"].cancel()
        if websocket in connection_states:
            del connection_states[websocket]

async def handle_conversation_flow(websocket: WebSocket, user_text: str, state: dict):
    if not user_text.strip(): return

    # ç¾åœ¨ã®å±¥æ­´ã‚’å–å¾—ï¼ˆstateã‹ã‚‰å‚ç…§ï¼‰
    history = state["history"]

    # ============================================
    # â˜… 1. åˆå›: ãƒ—ãƒªãƒ•ã‚§ãƒƒãƒæ¸ˆã¿éŸ³å£°ã‚’å³å›å
    # ============================================
    if state["is_first_interaction"]:
        print("[åˆå›] åº—å“¡ã®ç¬¬ä¸€å£°ã‚’æ¤œçŸ¥ â†’ ãƒ—ãƒªãƒ•ã‚§ãƒƒãƒéŸ³å£°ã‚’å›å")
        state["is_first_interaction"] = False

        reserver_name = ai_engine.RESERVATION_INFO['reserver_name']
        default_intro = f"ãŠå¿™ã—ã„ã¨ã“ã‚æã‚Œå…¥ã‚Šã¾ã™ã€‚ç§ã€{reserver_name}ã®AIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚äºˆç´„ã‚’ãŠé¡˜ã„ã§ãã¾ã™ã§ã—ã‚‡ã†ã‹ã€‚"

        greeting_text = getattr(ai_engine, "INTRO_TEXT", default_intro)

        # ã‚¨ã‚³ãƒ¼åˆ¤å®šç”¨ã«SSMLã‚¿ã‚°ã‚’é™¤å»ã—ãŸãƒ†ã‚­ã‚¹ãƒˆã‚’ä¿å­˜
        state["current_ai_text"] = re.sub(r'<[^>]+>', '', greeting_text)

        # å±¥æ­´ã«è¿½åŠ 
        history.append({"role": "user", "text": user_text})
        history.append({"role": "ai", "text": greeting_text})

        # NOTE: ãƒ—ãƒªãƒ•ã‚§ãƒƒãƒéŸ³å£°ã®å›åã¯ã€ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆãªã—ã§å®Œäº†ã‚’å¾…ã¤
        try:
            ai_audio = await state["intro_task"]

            if ai_audio:
                print(f"ğŸš€ [å³ç­”] ç¬¬ä¸€å£°ã‚’é€ä¿¡: {greeting_text[:10]}...")
                await send_json_safe(websocket, {"type": "audio", "text": greeting_text, "audio": ai_audio})
            else:
                print("âŒ ç¬¬ä¸€å£°ã®ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸ")
        except Exception as e:
            print(f"âŒ ã‚¿ã‚¹ã‚¯å¾…æ©Ÿã‚¨ãƒ©ãƒ¼: {e}")

        return # Geminiã¯å‘¼ã°ãªã„

    # ============================================
    # â˜… 2. é€šå¸¸: ç›¸æ§Œ + Gemini
    # ============================================

    # --- ç›¸æ§Œ ---
    ack_text = ""
    try:
        ack_text, _ = await select_smart_ack_async(user_text)

        # ã‚¨ã‚³ãƒ¼åˆ¤å®šç”¨ã«SSMLã‚¿ã‚°ã‚’é™¤å»ã—ãŸãƒ†ã‚­ã‚¹ãƒˆã‚’ä¿å­˜
        state["current_ai_text"] = re.sub(r'<[^>]+>', '', ack_text)

        ack_audio = await synthesize_speech(ack_text)

        if ack_audio:
            await send_json_safe(websocket, {"type": "audio", "text": ack_text, "audio": ack_audio})

            # å›ºå®šã‚¦ã‚§ã‚¤ãƒˆ 0.5ç§’
            await asyncio.sleep(0.5) 

            # ãƒ‡ãƒãƒƒã‚°ãƒ­ã‚°ã¯SSMLé™¤å»æ¸ˆã¿ãƒ†ã‚­ã‚¹ãƒˆã‚’ä½¿ç”¨
            clean_ack_text = re.sub(r'<[^>]+>', '', ack_text)
            print(f"âœ… å³ç­”é€ä¿¡å®Œäº† (Wait: 0.5s): '{clean_ack_text}'")

    except Exception as e:
        print(f"âŒ ç›¸æ§Œã‚¨ãƒ©ãƒ¼: {e}")

    # --- Geminiå¿œç­” ---
    try:
        # LLMã«æ¸¡ã™å‰ã«å±¥æ­´ã‹ã‚‰SSMLã‚¿ã‚°ã‚’å‰Šé™¤ã™ã‚‹
        clean_history = clean_ssml_from_history(history)

        # Geminiå‡¦ç†ï¼ˆæˆ»ã‚Šå€¤ã® new_history ã‚’å—ã‘å–ã‚‹ï¼‰
        ai_text, new_history = await process_conversation_async(user_text, clean_history)

        # æ–°ã—ã„å±¥æ­´ã‚’ state ã«ä¿å­˜ã—ã¦æ°¸ç¶šåŒ–ã™ã‚‹
        state["history"] = new_history 

        # é‡è¤‡ã‚«ãƒƒãƒˆ
        clean_ack_text = re.sub(r'<[^>]+>', '', ack_text)

        if clean_ack_text and ai_text.startswith(clean_ack_text):
            ai_text = ai_text[len(clean_ack_text):].strip()
            if ai_text.startswith("ã€‚") or ai_text.startswith("ã€"):
                ai_text = ai_text[1:].strip()

        print(f"ğŸ¤– AI(æœ¬é¡Œ): {ai_text}")

        # ã€ä¿®æ­£ç®‡æ‰€ã€‘ç©ºæ–‡å­—åˆ—ã‚„å¥èª­ç‚¹ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã‚’å‰Šé™¤ã—ã€LLMã®å¿œç­”ã‚’ãã®ã¾ã¾ä½¿ç”¨ã™ã‚‹
        if not ai_text: 
            # LLMãŒç©ºæ–‡å­—åˆ—ã‚’è¿”ã—ãŸå ´åˆã¯ã€ãã®ã¾ã¾ç„¡è¨€ã§çµ‚äº†ã™ã‚‹ï¼ˆæ²ˆé»™ï¼‰
            return

        state["current_ai_text"] = ai_text
        ai_audio = await synthesize_speech(ai_text)
        if ai_audio:
            await send_json_safe(websocket, {"type": "audio", "text": ai_text, "audio": ai_audio})

            # LLMå¿œç­”ï¼ˆæœ¬é¡Œï¼‰ã®å¾Œã‚‚ã‚¦ã‚§ã‚¤ãƒˆã‚’å…¥ã‚Œã‚‹
            await asyncio.sleep(2.0) 

    except Exception as e:
        print(f"âŒ AIã‚¨ãƒ©ãƒ¼: {e}")

if __name__ == "__main__":
    uvicorn.run(app, host="0.0.0.0", port=5000)
